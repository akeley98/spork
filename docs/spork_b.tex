% exocc b_samples.py && python3 code_to_tex.py b_samples.py b_samples && xelatex spork_b.tex </dev/null
\input{whitepaper_common.tex}

\tikzstyle{redstyle} = [draw=redBoxFg, fill=redBoxBg, text=redBoxFg]
\tikzstyle{yellowstyle} = [draw=yellowBoxFg, fill=yellowBoxBg, text=yellowBoxFg]
\tikzstyle{greenstyle} = [draw=greenBoxFg, fill=greenBoxBg, text=greenBoxFg]
\tikzstyle{bluestyle} = [draw=blueBoxFg, fill=blueBoxBg, text=blueBoxFg]
\tikzstyle{violetstyle} = [draw=violetBoxFg, fill=violetBoxBg, text=violetBoxFg]
\tikzstyle{nRedstyle} = [draw=nRedBoxFg, fill=nRedBoxBg, text=nRedBoxFg]
\tikzstyle{nGoldstyle} = [draw=nGoldBoxFg, fill=nGoldBoxBg, text=nGoldBoxFg]
\tikzstyle{nGreenstyle} = [draw=nGreenBoxFg, fill=nGreenBoxBg, text=nGreenBoxFg]
\tikzstyle{nBluestyle} = [draw=nBlueBoxFg, fill=nBlueBoxBg, text=nBlueBoxFg]
\tikzstyle{nPurplestyle} = [draw=nPurpleBoxFg, fill=nPurpleBoxBg, text=nPurpleBoxFg]

\tikzstyle{CollTypeExampleStyle} = [rectangle, draw=black, text centered, text width=20mm]

\begin{document}

% Kernel launch \& loops:
% CudaDeviceFunction defines clusterDim & blockDim
% Loops: seq, cuda_task, cuda_threads (loop mode)
% nest of cuda_tasks loops in CudaDeviceFunction. Inner-most body is device task; one instance of the body is assigned to one cluster.
% Within the device task, each instance of a stmt is executed by a set of threads within the cluster (thread collective)
% cuda_threads(0, c_{hi}, unit=...) loop subdivides its executing thread collective into c_{hi}-many disjoint thread collectives, guided by the unit parameter.
% Uniform execution encoded in language.
%
% Collective Types
% cuda_threads loop takes a collective unit from which a collective type \delta is unpacked (section link).
% Collective type encodes number and arrangement of threads (e.g. warp, CTA, CTA pair).
% In typical case, the thread collectives assigned to iteration is described by \delta (section link).
% Local thread index, thread collective need not be contiguous range of local thread indices.
% Lexicographical ordering wrt domain.
% Box and so on.
%
% Distributed Memory
% Thread pitch is crucial concept.
% Thread pitch of iterator.
% Distributed memory; shard mapped to thread collectives described by \delta
% Thread pitch tuple, describes residency.
%
% Synchronization
% Read|Write -> Fence|Arrive
% Read|Write -> Await, when trailing bar
% Fence|Await -> Read
% Fence|Await -> Write
% Arrive -> Await

\myTitle{Exo-GPU (Spork) Guide}

\myChapterLink{sec:Overview}{Overview}

\myChapterLink{sec:CudaDeviceFunction}{Cuda Device Function \& Warp Specialization}

Launching kernels, distributing work to clusters with \lighttt{cuda\_tasks} loops, \lighttt{CudaWarps} blocks.

\myChapterLink{sec:CollTypes}{Collective Units \& Collective Types}

Modeling subdivisions of threads in the cluster, e.g. threads, warps, warpgroups, CTAs, CTA pairs.

\myChapterLink{sec:CollTiling}{Collective Tiling}

Distributing work to threads-in-cluster with \lighttt{cuda\_threads} loops.

\myChapterLink{sec:DistributedMemory}{Distributed Memory}

Sharding tensor and barrier allocations onto different groups of threads.

\myChapterLink{sec:Synchronization}{Synchronization}

\lighttt{Fence}, \lighttt{Arrive}, \lighttt{Await}, async instructions, timelines.

\myChapterLink{sec:Instructions}{Instructions}

\myChapterLink{sec:Glossary}{Glossary \& Reference}

\section{Overview}
\label{sec:Overview}


This document assumes knowledge of CPU-only Exo.
We describe the concepts of the GPU extension.
All Exo code continues to be CPU code by default (we say that such code is at \myKeyA{CPU-scope}).
To move code to the GPU, wrap it inside a \lighttt{with CudaDeviceFunction} block (Section~\ref{sec:CudaDeviceFunction}); this defines the \lighttt{clusterDim} (number of CTAs per cluster, def~\ref{sec:gCluster}) and \lighttt{blockDim} (number of threads per CTA, def~\ref{sec:gCta}), and may also define \myKeyA{warp variables} (def~\ref{sec:gWarpVariable}) giving names to subcollections of warps (def~\ref{sec:gWarp}) for the purposes of warp specialization.
The statements within are at \myKeyA{CUDA scope} and are converted to CUDA C++ code.

We generalize loops in Exo to sequential and parallel for loops, distinguished by their \myKeyA{loop mode} (def~\ref{sec:gLoopMode}).
The body of the \lighttt{CudaDeviceFunction} block must contain only a single statement: a nest of one or more \lighttt{cuda\_tasks} loops.
The body of the inner-most \lighttt{cuda\_tasks} loop is a \myKeyA{device task}; one instance of the device task is assigned to one CUDA cluster for execution (see example~\ref{sec:gCudaDeviceFunction}).
Within the device task, each statement instance (def~\ref{sec:gStatementInstance}) is executed by a set of threads within the cluster; this is a \myKeyA{thread collective}.

A \lighttt{cuda\_threads(0, $c_\text{hi}$, unit=\_)} loop may appear anywhere inside a device task.
This statement divides its executing thread collective into $c_\text{hi}$-many disjoint subsets (possibly with some inactive threads left over), and assigns one to execute each iteration of the loop.
The \lighttt{unit} parameter is a \myKeyA{collective unit} (def~\ref{sec:gCollUnit}), from which a \myKeyA{collective type} $\delta$ is unpacked (Section~\ref{sec:CollTypes}).
The collective type describes a number and arrangement of threads (e.g. single thread, warp, CTA, CTA pair).
In the common case, the thread collectives assigned to each iteration are described by this unpacked $\delta$.

This design encodes uniform execution as a mostly syntactic property of the language.
When the thread collectives that execute instances of a statement are described by a collective type $\delta$, the compiler deduces that the statement is at $\delta$-scope (e.g. warp-scope, CTA-scope, as in the top of Figure~\ref{fig:OverviewThreads}).
The underlying static analysis for this is based on \myKeyA{local thread indices} (def~\ref{sec:gLocalThreadIndex}), which number the threads within a cluster lexicographically based on CTA index, then thread index.
The threads within a thread collective need not have a contiguous range of local thread indices (e.g., ``all even numbered CTAs in a cluster'' is a valid thread collective).

Based on this static analysis, we define a \myKeyA{collective tiling} (Section~\ref{sec:CollTiling}) and thread mapping function annotating each CUDA-scope statement, we define \myKeyA{distributed memory} (Section~\ref{sec:DistributedMemory}), which maps shards of an array onto different thread collectives for storage, and we define correct synchronization (Section~\ref{sec:Synchronization}), which we currently can check for a selection of concrete problem sizes.

\subsection{Distributed Memory Overview}

Each \lighttt{cuda\_threads} loop iterator indirectly defines a \myKeyA{thread pitch}.
This is the difference, in linear thread indices, between thread collectives assigned to consecutive loop iterations.
Distributed memory is deduced from the indexing pattern of an array, and attempts to map shards of the array into thread collectives described by the collective type specified by the memory type.
This flexibility allows memory to be sharded at different levels of the CUDA thread hierarchy (e.g. per-CTA shared memory shards, per-thread register shards).
The deduction assigns a thread pitch to each dimension; elements that are adjacent on a dimension are resident in thread collectives whose local thread indices differ by that dimension's thread pitch.
We define requirements for distributed memory deduction (Section~\ref{sec:DistributedMemory}); in particular, the iterator used to index a particular dimension must have the same thread pitch as that dimension (Figure~\ref{fig:OverviewThreads}, bottom).

\begin{figure}[t]
\codehrule
\input{b_samples/OverviewThreads.0.tex}
\caption{Threads \& Distributed Memory Example Code}
\label{fig:OverviewThreads}
\codehrule
\end{figure}

\subsection{Synchronization Overview}

Exo-GPU introduces synchronization statements: \lighttt{Fence}, \lighttt{Arrive}, and \lighttt{Await}, as well as the ability to allocate barrier variables, which control pairing between \lighttt{Arrive} and \lighttt{Await} statements.
Like other Exo statements, threads execute synchronization statements in program order.

We view each memory access (read or write) as being performed by a certain thread collective and \myKeyA{qualitative timeline} (\textsf{QualTL}, \ref{sec:gQualTL}).
We need this latter attribute to be able to reason about async instructions; the qualitative timeline of a memory access varies depending on what instruction performs the access.

A \lighttt{Fence} statement instance synchronizes the threads within the thread collective that executes it, e.g. a \lighttt{Fence} at warp-scope corresponds to a \lighttt{\_\_syncwarp}-like construct, and a \lighttt{Fence} at CTA-scope corresponds to a \lighttt{\_\_syncthreads}-like construct (Figure~\ref{fig:OverviewSyncExample}).
``Paired'' instances of an \lighttt{Arrive} and an \lighttt{Await} statement implement a split-barrier construct.
We use this syntax:

\hphantom{spacing}
\texttt{Fence($\tau_s^\mathrm{pre}, \tau_s^\mathrm{post}$)}
\hfill
\texttt{Arrive($\tau_s^\mathrm{pre}$) >}\texttt{> $z$}
\hfill
\texttt{Await($z, \tau_s^\mathrm{post}, n$)}
\hphantom{spacing}

where $\tau_s^\mathrm{pre}$ and $\tau_s^\mathrm{post}$ are \myKeyA{sync timelines} (\textsf{SyncTL}, \ref{sec:gSyncTL}), which filter the set of qualitative timelines of memory accesses that are synchronized, and $z$ and $n$ are a barrier variable read and an integer, which together control pairing of executed \lighttt{Arrive} and \lighttt{Await} instances.

The barrier variable itself is allocated with the syntax ``\texttt{<name>: barrier[$n^*$] @ $\pi_z$}'', where $n^*$ defines the array size of the barrier variable and $\pi_z$ defines the completion mechanism (\lighttt{CudaMbarrier}, \lighttt{CudaCommitGroup}, or \lighttt{CudaClusterSync}).
The array is subject to distributed memory analysis.

The goal of synchronization checking is to validate \myKeyA{sequential-parallel equivalence}.
The semantics of an Exo program (which defines the numerical outputs) continue to be defined sequentially; we can, in a sense, view the new Exo-GPU constructs as ``annotations'' on sequential code.
In particular, the semantics of parallel loops are identical to sequential loops, and async instruction calls are interpreted as if they were non-async instructions.
We want to convince ourselves that the generated parallel CUDA program generates the outputs that sequential semantics specify it will output.

Although this is not the formulation formally used by the abstract machine used for synchronization checking (Section~\ref{sec:Synchronization}), it's useful to reason about correctness in terms of dependency edges between statement instances.
Take a sequential trace of an Exo-GPU program, decomposed into reads and writes to array elements, and instances of \lighttt{Fence}, \lighttt{Arrive}, \lighttt{Await}.
For each pair of reads/writes to the same array element (other than two reads) to be safe, there must be a path from the earlier read/write to the later read/write via dependency edges.
Given the statement to the left of the $\to$ appears earlier in the sequential trace than the statement to the right, and there is a thread in common to their executing thread collectives, we have the following dependency edges.
Italicized values are defined in Section~\ref{sec:Synchronization}.

\begin{itemize}
  \item \texttt{Read|Write $\to$ Read|Write}\\when the prior memory access is not \emph{out-of-order}, and the prior memory access uses a qualitative timeline that is in the \emph{extended qualitative timeline set} of the subsequent memory access.
  \item \texttt{Read|Mutate $\to$ Fence($\tau_s^\text{pre}$, \_)|Arrive($\tau_s^\text{pre}$) >}\texttt{> \_}\\when the qualitative timeline of the memory access is in the \textit{full timeline set} of $\tau_s^\text{pre}$.
  \item \texttt{Fence(\_, $\tau_s^\text{post}$)|Await(\_, $\tau_s^\text{post}$, \_) $\to$ Read}\\when the qualitative timeline of the read is in the \textit{full timeline set} of $\tau_s^\text{post}$.
  \item \texttt{Fence(\_, $\tau_s^\text{post}$)|Await(\_, $\tau_s^\text{post}$, \_) $\to$ Write}\\when the qualitative timeline of the read is in the \textit{temporal timeline set} of $\tau_s^\text{post}$.
  \item \texttt{Fence(\_, $\tau_s^\text{post}$)|Await(\_, $\tau_s^\text{post}$, \_) $\to$ Fence($\tau_s^\text{pre}$, \_)|Arrive($\tau_s^\text{pre}$) >}\texttt{> \_}\\when there is a qualitative timeline in common to the \textit{full timeline sets} of $\tau_s^\text{pre}$ and $\tau_s^\text{post}$, and $\tau_s^\text{post}$ is transitive.
\end{itemize}

Finally, there are dependency edges from instances of \lighttt{Arrive(\_) >}\lighttt{> $b$} and \lighttt{Await($b$, \_, \_)} defined by arrive/await pairing, and dependency edges from reads/writes to \lighttt{Await} instances directly for instructions that take a barrier directly (currently, only TMA-to-SMEM instructions).

\begin{figure}[h!]
\codehrule
\input{b_samples/OverviewSyncExample.0.tex}
\caption{Examples of Synchronization Statements}
\label{fig:OverviewSyncExample}
\codehrule
\end{figure}




\FloatBarrier
\newpage
\section{Cuda Device Function \& Warp Specialization}
\label{sec:CudaDeviceFunction}

Wrap code with a \lighttt{with CudaDeviceFunction(...):} statement to transform it to CUDA.
The body of the \lighttt{CudaDeviceFunction} statement must consist of exactly one statement: a nest of one or more \lighttt{cuda\_tasks} loops.
The body of the inner-most \lighttt{cuda\_tasks} loop is a \myKeyA{device task}; each is assigned to a CUDA cluster for execution.
We implement a persistent-kernel design, so multiple tasks may be co-located on the same cluster.
The shape of the \lighttt{cuda\_tasks} iteration space must be a cuboid, i.e., the loop bounds of one \lighttt{cuda\_tasks} loop must not be dependent on another \lighttt{cuda\_tasks} loop.

The \lighttt{CudaDeviceFunction} object is a Python object, containing attributes
\begin{itemize}
  \item \lighttt{clusterDim} (default 1), number of CTAs per cluster.
  \item \lighttt{blocks\_per\_sm} (default 1), number of CTAs concurrently executing per hardware SM.
  \item \lighttt{blockDim}, number of threads per CTA.
  \item \lighttt{warp\_config}, list of \lighttt{CudaWarpConfig} objects.
\end{itemize}
Exactly one of \lighttt{blockDim} or \lighttt{warp\_config} must be given.
The latter is intended for kernels with warp specialization, where we partition the warps in the CTA into named groups of warps, possibly with a different number of registers each.
Each \lighttt{CudaWarpConfig} defines a \myKeyA{warp variable}, and has attributes
\begin{itemize}
  \item \lighttt{name: str}, the name of the warp variable.
  \item \lighttt{count: int}, number of warps.
  \item \lighttt{setmaxnreg\_dec: Optional[int]}, registers per thread; regs allocated by \lighttt{setmaxnreg.dec}.
  \item \lighttt{setmaxnreg\_inc: Optional[int]}, registers per thread; regs allocated by \lighttt{setmaxnreg.inc}.
\end{itemize}
The \lighttt{blockDim} of the CTA is implicitly 32 times the sum of the number of warps defined.
Within the device task, a \lighttt{with CudaWarps(name=<str>)} statement may be used to restrict the body of the statement to only execute on the subset of warps named (Figure~\ref{fig:CudaDeviceFunction0}).

\begin{figure}[h]
\codehrule
\input{b_samples/CudaDeviceFunction.0.tex}
\caption{Kernel launch with warp specialization}
\label{fig:CudaDeviceFunction0}
\codehrule
\end{figure}

\FloatBarrier
\newpage
\section{Collective Units \& Collective Types}
\label{sec:CollTypes}

We use collective types $\delta$ to describe a quantity and arrangement of threads within a cluster, such as ``single thread'', ``warp'', ``CTA'', ``one warp from a pair of CTAs''.
These are unpacked from a collective unit $\tau_u$ defined in the frontend language (def~\ref{sec:gCollUnit}).
A collective type consists of two equal-length tuples: a domain and a box.
The dimension $M$ of the collective type is the length of these tuples.
The \myKeyA{domain} ($\delta.D_0...\delta.D_{M-1}$): $\mathbb{N}_{\ge2}^M$ describes an organization of the threads in a cluster into an $M$-dimensional grid.
The \myKeyA{box} ($\delta.B_0...\delta.B_{M-1}$): $\mathbb{N}_\top^M$ describes the number of threads on each dimension to select (the special value $\top$ indicates ``no requirement'').

We first define a linear ordering of threads in a cluster, then extend to multidimensional coordinates.
The local thread index of a thread is \lighttt{cluster\_ctarank * blockDim.x + threadIdx.x}
i.e., the threads in a cluster are numbered in (\lighttt{cluster\_ctarank, threadIdx.x})-lexicographical order (Exo-GPU parallelizes on the x dimension only).

For a given domain, we derive the \myKeyA{dimension thread pitch} $\delta.P_i$:
\begin{align*}
    \delta.P_i = \prod_{k=i+1}^{M-1} \delta.D_k
\end{align*}
and we define the mapping $\mathsf{toLocal}(D, c)$ (def~\ref{sec:gToLocal}), which converts a domain $D$ and coordinates $c$ to a local thread index; the coordinates $[0, \delta.D_0-1]_\mathbb{N} \times ... \times [0, \delta.D_{M-1}-1]_\mathbb{N}$ get mapped to local thread indices in lexicographical order.
The product of the domain coordinates $\delta.D_0 \times ... \times \delta.D_{M-1}$ must be equal to the number of threads in the cluster (\lighttt{clusterDim.x * blockDim.x}).

\subsection{Collective Types \& Thread Collectives}
\label{sec:CollTypeThreadCollective}

A thread collective is described by a collective type $\delta$ when all threads are in the same cluster, and, with $\mu: \mathcal{P}(\mathbb{N})$ being the set of local thread indices of the threads, there exist sets $C_0 ... C_{M-1}: \mathcal{P}(\mathbb{N})$ such that
\begin{itemize}
  \item $C_i \subseteq [0, \delta.D_i - 1]$
  \item $\delta.B_i \ne \top \implies \exists x.\; C_i = [x, x + \delta.B_i - 1]_\mathbb{N}$.
  \item $\mu = \{ \mathsf{toLocal}(\delta.D, c) \mid c \in C_0 \times ... \times C_{M-1}\}$
\end{itemize}
If we have no $\top$ box coordinates, this is specifying that the thread collective forms a cuboid of dimensions $\delta.B_0 \times ... \times \delta.B_{M-1}$ when its threads are arranged in the grid implied by $\delta.D$; therefore, the number of threads in the thread collective is the product of the box coordinates (Figure~\ref{fig:CollTypeExample}).

\begin{figure}[h!]
\sffamily
\begin{tikzpicture}[node distance=0mm]
\node(t000a) [CollTypeExampleStyle] {(0, 0)\\0 $ \in \mu$\\0, 0, 0, 0};
\node(t000b) [CollTypeExampleStyle, right=of t000a, xshift=6mm] {(0, 127)\\127 $ \in \mu$\\0, 0, 0, 127};
\draw [dotted] (t000a) -- (t000b);
\node(t001a) [CollTypeExampleStyle, right=of t000b, xshift=2mm, yshift=-3mm] {(0, 128)\\128 $ \in \mu$\\0, 0, 1, 0};
\node(t001b) [CollTypeExampleStyle, right=of t001a, xshift=6mm] {(0, 255)\\255 $ \in \mu$\\0, 0, 1, 127};
\draw [dotted] (t001a) -- (t001b);
\node(t002a) [CollTypeExampleStyle, right=of t001b, xshift=2mm, yshift=-3mm] {(0, 256)\\256 $ \in \mu$\\0, 0, 2, 0};
\node(t002b) [CollTypeExampleStyle, right=of t002a, xshift=6mm] {(0, 383)\\383 $ \in \mu$\\0, 0, 2, 127};
\draw [dotted] (t002a) -- (t002b);
\node(t010a) [CollTypeExampleStyle, below=of t000a, yshift=-2mm] {(1, 0)\\384 $ \in \mu$\\0, 1, 0, 0};
\node(t010b) [CollTypeExampleStyle, right=of t010a, xshift=6mm] {(1, 127)\\511 $ \in \mu$\\0, 1, 0, 127};
\draw [dotted] (t010a) -- (t010b);
\node(t011a) [CollTypeExampleStyle, right=of t010b, xshift=2mm, yshift=-3mm] {(1, 128)\\512 $ \in \mu$\\0, 1, 1, 0};
\node(t011b) [CollTypeExampleStyle, right=of t011a, xshift=6mm] {(1, 255)\\639 $ \in \mu$\\0, 1, 1, 127};
\draw [dotted] (t011a) -- (t011b);
\node(t012a) [CollTypeExampleStyle, right=of t011b, xshift=2mm, yshift=-3mm] {(1, 256)\\640 $ \in \mu$\\0, 1, 2, 0};
\node(t012b) [CollTypeExampleStyle, right=of t012a, xshift=6mm] {(1, 383)\\767 $ \in \mu$\\0, 1, 2, 127};
\draw [dotted] (t012a) -- (t012b);

\node(t100a) [CollTypeExampleStyle, below=of t010a, yshift=-4mm, xshift=-4mm] {(2, 0)\\768 $ \in \mu$\\1, 0, 0, 0};
\node(t100b) [CollTypeExampleStyle, right=of t100a, xshift=6mm] {(2, 127)\\895 $ \in \mu$\\1, 0, 0, 127};
\draw [dotted] (t100a) -- (t100b);
\node(t101a) [CollTypeExampleStyle, right=of t100b, xshift=2mm, yshift=-3mm] {(2, 128)\\896 $ \in \mu$\\1, 0, 1, 0};
\node(t101b) [CollTypeExampleStyle, right=of t101a, xshift=6mm] {(2, 255)\\1023 $ \in \mu$\\1, 0, 1, 127};
\draw [dotted] (t101a) -- (t101b);
\node(t102a) [greenstyle, CollTypeExampleStyle, right=of t101b, xshift=2mm, yshift=-3mm] {(2, 256)\\1024 $ \in \mu$\\1, 0, 2, 0};
\node(t102b) [greenstyle, CollTypeExampleStyle, right=of t102a, xshift=6mm] {(2, 383)\\1151 $ \in \mu$\\1, 0, 2, 127};
\draw [dotted] (t102a) -- (t102b);
\node(t110a) [CollTypeExampleStyle, below=of t100a, yshift=-2mm] {(3, 0)\\1152 $ \in \mu$\\1, 1, 0, 0};
\node(t110b) [CollTypeExampleStyle, right=of t110a, xshift=6mm] {(3, 127)\\1279 $ \in \mu$\\1, 1, 0, 127};
\draw [dotted] (t110a) -- (t110b);
\node(t111a) [CollTypeExampleStyle, right=of t110b, xshift=2mm, yshift=-3mm] {(3, 128)\\1280 $ \in \mu$\\1, 1, 1, 0};
\node(t111b) [CollTypeExampleStyle, right=of t111a, xshift=6mm] {(3, 255)\\1407 $ \in \mu$\\1, 1, 1, 127};
\draw [dotted] (t111a) -- (t111b);
\node(t112a) [greenstyle, CollTypeExampleStyle, right=of t111b, xshift=2mm, yshift=-3mm] {(3, 256)\\1408 $ \in \mu$\\1, 1, 2, 0};
\node(t112b) [greenstyle, CollTypeExampleStyle, right=of t112a, xshift=6mm] {(3, 383)\\1535 $ \in \mu$\\1, 1, 2, 127};
\draw [dotted] (t112a) -- (t112b);

\node(t200a) [CollTypeExampleStyle, below=of t110a, yshift=-4mm, xshift=-4mm] {(4, 0)\\1536 $ \in \mu$\\2, 0, 0, 0};
\node(t200b) [CollTypeExampleStyle, right=of t200a, xshift=6mm] {(4, 127)\\1663 $ \in \mu$\\2, 0, 0, 127};
\draw [dotted] (t200a) -- (t200b);
\node(t201a) [CollTypeExampleStyle, right=of t200b, xshift=2mm, yshift=-3mm] {(4, 128)\\1664 $ \in \mu$\\2, 0, 1, 0};
\node(t201b) [CollTypeExampleStyle, right=of t201a, xshift=6mm] {(4, 255)\\1791 $ \in \mu$\\2, 0, 1, 127};
\draw [dotted] (t201a) -- (t201b);
\node(t202a) [CollTypeExampleStyle, right=of t201b, xshift=2mm, yshift=-3mm] {(4, 256)\\1792 $ \in \mu$\\2, 0, 2, 0};
\node(t202b) [CollTypeExampleStyle, right=of t202a, xshift=6mm] {(4, 383)\\1919 $ \in \mu$\\2, 0, 2, 127};
\draw [dotted] (t202a) -- (t202b);
\node(t210a) [CollTypeExampleStyle, below=of t200a, yshift=-2mm] {(5, 0)\\1920 $ \in \mu$\\2, 1, 0, 0};
\node(t210b) [CollTypeExampleStyle, right=of t210a, xshift=6mm] {(5, 127)\\2047 $ \in \mu$\\2, 1, 0, 127};
\draw [dotted] (t210a) -- (t210b);
\node(t211a) [CollTypeExampleStyle, right=of t210b, xshift=2mm, yshift=-3mm] {(5, 128)\\2048 $ \in \mu$\\2, 1, 1, 0};
\node(t211b) [CollTypeExampleStyle, right=of t211a, xshift=6mm] {(5, 255)\\2175 $ \in \mu$\\2, 1, 1, 127};
\draw [dotted] (t211a) -- (t211b);
\node(t212a) [CollTypeExampleStyle, right=of t211b, xshift=2mm, yshift=-3mm] {(5, 256)\\2176 $ \in \mu$\\2, 1, 2, 0};
\node(t212b) [CollTypeExampleStyle, right=of t212a, xshift=6mm] {(5, 383)\\2303 $ \in \mu$\\2, 1, 2, 127};
\draw [dotted] (t212a) -- (t212b);

\node(t300a) [CollTypeExampleStyle, below=of t210a, yshift=-4mm, xshift=-4mm] {(6, 0)\\2304 $ \in \mu$\\3, 0, 0, 0};
\node(t300b) [CollTypeExampleStyle, right=of t300a, xshift=6mm] {(6, 127)\\2431 $ \in \mu$\\3, 0, 0, 127};
\draw [dotted] (t300a) -- (t300b);
\node(t301a) [CollTypeExampleStyle, right=of t300b, xshift=2mm, yshift=-3mm] {(6, 128)\\2432 $ \in \mu$\\3, 0, 1, 0};
\node(t301b) [CollTypeExampleStyle, right=of t301a, xshift=6mm] {(6, 255)\\2559 $ \in \mu$\\3, 0, 1, 127};
\draw [dotted] (t301a) -- (t301b);
\node(t302a) [CollTypeExampleStyle, right=of t301b, xshift=2mm, yshift=-3mm] {(6, 256)\\2560 $ \in \mu$\\3, 0, 2, 0};
\node(t302b) [CollTypeExampleStyle, right=of t302a, xshift=6mm] {(6, 383)\\2687 $ \in \mu$\\3, 0, 2, 127};
\draw [dotted] (t302a) -- (t302b);
\node(t310a) [CollTypeExampleStyle, below=of t300a, yshift=-2mm] {(7, 0)\\2688 $ \in \mu$\\3, 1, 0, 0};
\node(t310b) [CollTypeExampleStyle, right=of t310a, xshift=6mm] {(7, 127)\\2815 $ \in \mu$\\3, 1, 0, 127};
\draw [dotted] (t310a) -- (t310b);
\node(t311a) [CollTypeExampleStyle, right=of t310b, xshift=2mm, yshift=-3mm] {(7, 128)\\2816 $ \in \mu$\\3, 1, 1, 0};
\node(t311b) [CollTypeExampleStyle, right=of t311a, xshift=6mm] {(7, 255)\\2943 $ \in \mu$\\3, 1, 1, 127};
\draw [dotted] (t311a) -- (t311b);
\node(t312a) [CollTypeExampleStyle, right=of t311b, xshift=2mm, yshift=-3mm] {(7, 256)\\2944 $ \in \mu$\\3, 1, 2, 0};
\node(t312b) [CollTypeExampleStyle, right=of t312a, xshift=6mm] {(7, 383)\\3071 $ \in \mu$\\3, 1, 2, 127};
\draw [dotted] (t312a) -- (t312b);

\node(legend) [rectangle, draw=black, text centered, text width=5cm, above=of t000a, xshift=40mm, yshift=2mm] {(cluster\_ctarank, threadIdx.x)\\linear thread index $\in \mu$\\coordinates};
\end{tikzpicture}
\caption{Example of a thread collective being described by the collective type $\delta$ with $\delta.B = (1, 2, 1, 128)$ and $\delta.D = (4, 2, 3, 128)$, which is a collective type in aligned form (def~\ref{sec:gAlignedForm}). \lighttt{clusterDim = 8} and \lighttt{blockDim = 384}. $\mu = \mathsf{toLocal}(\delta.D, [1, 1]_\mathbb{N} \times [0, 1]_\mathbb{N} \times [2, 2]_\mathbb{N} \times [0, 127]_\mathbb{N})$. This is one warpgroup per CTA of a CTA pair.}
\label{fig:CollTypeExample}
\end{figure}

\subsection{Collective Type Reshape}
\label{sec:CollTypeReshape}

Reshaping a collective type means to apply a series of dimension split operations to yield a new collective type.
We split the $k^{th}$ dimension of a collective type by a factor $f \in \mathbb{N}$ by
\begin{itemize}
  \item Inserting the coordinate pair $(\delta.D_k / f, f)$ in place of $\delta.D_k$.
  \item Inserting the coordinate pair $(\delta.B_k / f, f)$ in place of $\delta.B_k$, if $\delta.B_k \ne \top$ and $\delta.B_k \ge f$.
  \item Inserting the coordinate pair $(1, \delta.B_k)$ in place of $\delta.B_k$, if $\delta.B_k \ne \top$ and $\delta.B_k < f$.
  \item Inserting the coordinate pair $(\top, \top)$ in place of $\delta.B_k$, if $\delta.B_k = \top$.
\end{itemize}
e.g. if $\delta.D = (4, 384)$ and $\delta.B = (1, 128)$, then splitting dimension 1 by $32$ gives $\delta.D = (4, 12, 32)$ and $\delta.B = (1, 4, 32)$.

\subsection{Collective Unit to Collective Type}
\label{sec:CollUnit}

Collective units are also parameterized by a pair of $M$-tuples (domain and box), with coordinates being integer expressions of \lighttt{blockDim} and \lighttt{clusterDim}, or $\top$ in the case of the box.
This is represented in the frontend language as a Python \lighttt{CollUnit} object (the code consistently abbreviates ``collective'' as ``coll''), with $\top$ represented by \lighttt{None}.
We describe this further in def~\ref{sec:gCollUnit}.

\FloatBarrier
\newpage
\useMainSub
\section{Collective Tiling}
\label{sec:CollTiling}

The \lighttt{cuda\_tasks} loops assign instances of device tasks (def~\ref{sec:gDeviceTask}) to different clusters on the system, and the user has no control (yet) over the mapping between device tasks and clusters.
On the other hand, the \lighttt{cuda\_threads} loop, which assigns work to threads within a cluster, provides the user with tight control over this work mapping.

Each statement at CUDA scope (def~\ref{sec:gCudaScope}) has a deduced \myKeyA{collective tiling} attribute.
The collective tiling describes an arrangement of the threads in the cluster into a multidimensional space, in the same manner as a collective type's domain (def~\ref{sec:gDomain}), and groups \lighttt{cuda\_threads} loop iterators by the dimension they operate on.
The statement's collective tiling may be converted to
\begin{itemize}
  \item an \myKeyA{output collective type}.
    The thread collective assigned to execute an instance of this statement will always be described (Section~\ref{sec:CollTypeThreadCollective}) by this collective type.
  \item a \myKeyA{thread mapping function} of type $\Sigma_c \to \mathcal{P}(\mathbb{N})$; this converts the control environment $\sigma_c:\Sigma_c$ (i.e. $\sigma_c: \mathbb{Y} \to \mathbb{Z}$; the per-control-variable values) to the local thread indices (def~\ref{sec:gLocalThreadIndex}) of the thread collective assigned to execute an instance of this statement.
  NB this is using syntax from the PLDI submission.
  \item a per-\lighttt{cuda\_threads} iterator \myKeyA{thread pitch}: $\mathbb{N}$ (def~\ref{sec:gThreadPitch}).
  \item a per-\lighttt{cuda\_threads} iterator \myKeyA{tiled dimension index}: $\mathbb{N}_\bot$.
\end{itemize}
The domain and box of a collective tiling $\omega$ are that of its output collective type, and for brevity, we denote it as $\omega.D$ and $\omega.B$ respectively.

\subsection{Collective Tiling State}
\label{sec:CollTilingState}

A collective tiling $\omega: \Omega$ (of some dimensionality $M$) is an $M$-tuple of \myKeyA{collective dimension descriptors} $(\omega_0 ... \omega_{M-1})$.
Each descriptor $\omega_i$ consists of
\begin{itemize}
  \item $\omega_i.n: \mathbb{N}$, dimension extent
  \item $\omega_i.\textit{ops}: \mathcal{O}^*$, tuple of \myKeyA{collective dimension operators}
\end{itemize}
where $\mathcal{O}$ is $\mathbb{Y} \times \mathbb{N}^3$, with each attribute denoted as
\begin{itemize}
  \item $\omega_i.\textit{ops}_j.\textit{iter}: \mathbb{Y}$ (name of a control variable; no two ops in $\omega$ can have the same \textit{iter})
  \item $\omega_i.\textit{ops}_j.\textit{offset}: \mathbb{N}$
  \item $\omega_i.\textit{ops}_j.\textit{box}: \mathbb{N}$
  \item $\omega_i.\textit{ops}_j.\textit{tileCount}: \mathbb{N}$
\end{itemize}
The \myKeyA{output collective type} of $\omega$ is a collective type $(\omega.D, \omega.B)$ defined by
\begin{itemize}
  \item $\omega.D_i = \omega_i.n$
  \item $\omega.B_i$ is $\omega_i.n$ if $\omega_i.\textit{ops}$ is empty, otherwise it is the $\textit{box}$ of the last op.
  \item (recall dimension thread pitch values $\omega.P_i$ are implicit, as in def~\ref{sec:gThreadPitch}).
\end{itemize}
The \myKeyA{thread mapping function} selects, for each collective dimension descriptor $\omega_i$, an interval of size $\omega.B_i$ based on an affine transform of the values of the iterators associated with that dimension.
These intervals together select a sub-grid of the $M$-dimensional space of threads-in-cluster.

We derive the thread mapping from $\omega$ based on the function
\begin{align*}
    & \textsf{collMap}: \Omega \to \Sigma_c \to \mathcal{P}(\mathbb{N}) \\
    & (\omega_0, ..., \omega_{M-1}) \mapsto \sigma_c \mapsto \{ \textsf{toLocal}(\omega.D, c) \mid
      c \in [x_0, x_0 + \omega.B_0 - 1]_\mathbb{N} \times ... \times
            [x_{M-1}, x_{M-1} + \omega.B_{M-1} - 1]_\mathbb{N} \} \\
    & \text{ with } x_i = \sum_{\textit{op} \in \omega_i.\textit{ops}} \textit{op}.\textit{offset} + \sigma_c(\textit{op}.\textit{iter}) \textit{op}.\textit{box}
\end{align*}
where \textsf{toLocal} is def~\ref{sec:gToLocal} and the actual thread mapping function is $\textsf{collMap}(\omega)$ (partial evaluation).

For a given $y: \mathbb{Y}$, let $\textit{op}_y = \omega_i.\textit{ops}_j$ such that $y = \textit{op}_y.\textit{iter}$, if it exists.
The \myKeyA{thread pitch} and \myKeyA{tiled dimension index} of $y: \mathbb{Y}$ as defined by $\omega$ is
\begin{itemize}
  \item 0 and $i$, if $\textit{op}_y$ exists and $\textit{op}_y.\textit{tileCount} \le 1$
  \item $(\omega.P_i)(\textit{op}_y.\textit{box})$ and $i$, if $\textit{op}_y$ exists and $\textit{op}_y.\textit{tileCount} > 1$
  \item 0 and $\bot$ if $\textit{op}_y$ does not exist.
\end{itemize}

\subsection{Collective Tiling Reshape \& Domain Completion}
\label{sec:CollTilingReshape}

Similar to collective types (Section~\ref{sec:CollTypeReshape}), collective tilings may be reshaped by splitting dimensions.
We split the $k^{th}$ dimension of $\omega$ by a factor $f: \mathbb{N}$ by replacing the collective dimension descriptor $\omega_k$ with a pair $(\omega_\text{hi}, \omega_\text{lo})$ defined by
\begin{itemize}
  \item $\omega_\text{hi}.n = \omega_k.n / f$
  \item $\omega_\text{hi}.\textit{ops}$ is all $\textit{op} \in \omega_k.\textit{ops}$ with $\textit{op}.\textit{box} \ge f$, modified by dividing both $\textit{op}.\textit{box}$ and $\textit{op}.\textit{offset}$ by $f$. This fails if any division gives a non-integer.
  \item $\omega_\text{lo}.n = f$
  \item $\omega_\text{lo}.\textit{ops}$ is all $\textit{op} \in \omega_k.\textit{ops}$ with $\textit{op}.\textit{box} < f$, unmodified.
\end{itemize}

This mirrors Section~\ref{sec:CollTypeReshape}, in that this results in the single domain coordinate $\omega.D_k$ being replaced with $\omega.D_k / f$ and $f$.
We use the function $\textsf{domainCompletion}: \Omega \times \Delta \to \Omega \times \Delta$ (TODO define) to reshape a collective tiling and a collective type so that they have the same domain.

\subsection{Derived Collective Tilings}
\label{sec:DerivedCollTiling}

The collective tiling of each statement is the same as that of its parent, except that \lighttt{with CudaDeviceFunction}, \lighttt{for cuda\_threads}, and \lighttt{with CudaWarps} assign a new collective tiling for their children.
The latter two are defined based on the \textsf{deriveCollTiling} function (TODO define); here we just summarize the collective tilings.

\subsection{CudaDeviceFunction}
\label{sec:CollTilingCudaDeviceFunction}

If \lighttt{clusterDim = 1}, then $\omega$ is one-dimensional, with $\omega_0.n = \lighttt{blockDim}$.
Otherwise, $\omega$ is two-dimensional, with $\omega_0.n = \lighttt{clusterDim}$ and $\omega_1.n = \lighttt{blockDim}$.
In both cases, $\omega_*.\textit{ops}$ is empty.

\subsection{cuda\_threads Loops}
\label{sec:CollTilingCudaThreads}

A \lighttt{cuda\_threads} loop must be in the form \lighttt{for $y$ in cuda\_threads(0, $c_\text{hi}$, unit=$\tau_u$)}, with $c_\text{hi}$ a positive constant integer.
Let $\omega_\text{raw}$ be the collective tiling of the loop statement, and let $\delta_\text{raw}$ be the collective type unpacked from $\tau_u$ without alignment and without 1-padding (def~\ref{sec:gCollUnit}).
Let $(\omega, \delta) = \textsf{domainCompletion}(\omega_\text{raw}, \delta_\text{raw})$ so that $\omega$ and $\delta$ have the same domain.

The tiled dimension index $k$ is the value such that $\delta.B_k \notin \{ \top, \omega.B_k, \omega.D_k \}$.
If no such $k$ exists, then the collective tiling of the child statements is $\omega$, and $c_\text{hi}$ must be 1 (trivial tiling).

If multiple such $k$ exist, then the loop is ill-formed (ambiguous tiling).

If $k$ exists uniquely, then we must have $c_\text{hi} \delta.B_k \le \omega.B_k$, otherwise the loop is ill-formed (not enough threads).
In this case, the collective tiling $\omega'$ of the child statements is like $\omega$, but with a new $\textit{op}: \mathcal{O}$ appended to $\omega'_k.\textit{ops}$, with
\begin{itemize}
  \item $\textit{op}.\textit{iter} = y$
  \item $\textit{op}.\textit{offset} = 0$
  \item $\textit{op}.\textit{box} = \delta.B_k$
  \item $\textit{op}.\textit{tileCount} = c_\text{hi}$
\end{itemize}
so that the output collective type of $\omega'$ is the same as that of $\omega$, except that $\omega'.B_k = \delta.B_k$.
If all other box coordinates of $\omega'$ already match those of $\delta$, then the output collective type of $\omega'$ is $\delta$.
This is commonly the case, but we designed this to allow for mismatches on dimensions other than $k$ to make it easier to place CTA-in-cluster loops inside thread-in-CTA loops or \lighttt{with CudaWarps} blocks.

\subsection{CudaWarps}
\label{sec:CollTilingCudaWarps}

% Pants-on-fire simplified explanation for the end user.
We describe this somewhat informally in terms of the \lighttt{cuda\_threads} loop behavior.
A \lighttt{with CudaWarps(lo, hi, name=...)} statement has the following defaults:
\begin{itemize}
  \item \lighttt{lo = 0} if not given.
  \item \lighttt{hi}, if not given, is the number of warps of the warp variable named.
  \item \lighttt{name} is \lighttt{""} if this is a top-level case (see below), or the same as the parent \lighttt{with CudaWarps} statement if this is a leaf case.
\end{itemize}

\lighttt{with CudaWarps} statements that appear in CUDA device functions with at least two warp variables and with no other \lighttt{with CudaWarps} as a direct or indirect parent are a top-level case.
A top-level case must appear in \lighttt{cuda\_agnostic\_intact\_cta}-scope (def~\ref{sec:gCollUnit}).
The \lighttt{true\_lo} and \lighttt{true\_hi} of the statement are \lighttt{lo + p} and \lighttt{hi + p}, \lighttt{p} being the prefix of the warp variable (def~\ref{sec:gWarpVariable}).
All other cases are leaf cases, which have \lighttt{true\_lo} and \lighttt{true\_hi} being the same as \lighttt{lo} and \lighttt{hi}.

The \lighttt{with CudaWarps} statement defines the collective tiling $\omega'$ of its child statements in a similar manner as \lighttt{for \_ in cuda\_threads(0, true\_hi, unit=cuda\_warp)}, except that the threads that would have executed iterations \lighttt{true\_lo} through \lighttt{true\_hi - 1} instead cooperate to execute the statement body.
The \lighttt{with CudaWarps} statement defines a dummy iterator variable $y$ and adds a new collective dimension operator to $\omega'$ for $y$ (except in case of a trivial tiling).

\FloatBarrier
\newpage
\section{Distributed Memory}
\label{sec:DistributedMemory}


\FloatBarrier
\newpage
\section{Synchronization}
\label{sec:Synchronization}


\FloatBarrier
\newpage
\section{Instructions}
\label{sec:Instructions}


\FloatBarrier
\newpage
\section{Glossary \& Reference}
\label{sec:Glossary}

% >A

\subsection{Aligned Form (Collective Type)}
\label{sec:gAlignedForm}

A collective type $\delta$ is in aligned form when all box coordinates $\delta.B_i$ satisfy $\delta.B_i \in \{\top, 1, \delta.D_i\}$.
If no box coordinate is $\top$, then if $\delta$ describes two thread collectives, those two thread collectives are either identical or disjoint.

% >B
% >C

\subsection{Cluster}
\label{sec:gCluster}
Group of \lighttt{clusterDim}-many CTAs (def~\ref{sec:gCta}) that execute concurrently on the same GPC, and can synchronize with cluster sync, or using mbarriers.
When \lighttt{clusterDim = 1} (which is the case by default for Exo-GPU), then CTA and cluster are synonymous.
The PTX variable \lighttt{cluster\_ctarank} is the 0-based index of the CTA in the cluster.

\subsection{Collective Type (Scope)}
\label{sec:gCollType}

Description of a certain number and arrangement of threads in a cluster, e.g. thread, warp, CTA (Section~\ref{sec:CollTypes}).
A collective type $\delta$ has a certain dimensionality $M$, and consists of
\begin{itemize}
  \item domain, $\delta.D: \mathbb{N}_{\ge2}^M$ (coordinates are natural numbers at least 2).
  \item box, $\delta.B: \mathbb{N}_\top^M$ (coordinates are natural numbers or $\top$).
\end{itemize}
As well as implied dimension thread pitch values $\delta.P$ (def~\ref{sec:gThreadPitch}).
A statement is at $\delta$-scope when it is in CUDA scope (def~\ref{sec:gCudaScope}) and the thread collectives assigned to execute instances of that statement are always described by $\delta$ (Section~\ref{sec:CollTypeThreadCollective}).


\subsection{Collective Unit (Scope)}
\label{sec:gCollUnit}

Syntactic construct that wraps a collective type.
This may be parameterized based on \lighttt{blockDim} and \lighttt{clusterDim}.
A collective unit instance is $\tau_u$ in the grammar, and is an instance of \lighttt{CollUnit} in Python, with $\top$ represented by \lighttt{None} and other coordinate values represented by an instance of \lighttt{CollSizeExpr}.

A statement is at $\tau_u$-scope when it is in $\delta$-scope (def~\ref{sec:gCollType}), where $\delta$ is unpacked from $\tau_u$ with alignment and 1-padding; we define this after the table.

{
\footnotesize
\centering
\arraycolsep=1.8pt\def\arraystretch{1.0}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rrlll}
\toprule
& & & \emph{domain} & \emph{box} \\
$\tau_u : \mathrm{CollUnit} $ & $\Coloneqq$ &
  \texttt{standalone\_thread} & \texttt{(1,)} & \texttt{(1,)} \\
  &|& \texttt{$n_1$ * cuda\_thread} & \texttt{(blockDim,)} & \texttt{($n_1$,)} \\
  &|& \texttt{cuda\_quadpair} & \texttt{(blockDim/16, 16)} & \texttt{(2, 4)} \\
  &|& \texttt{$n_1$ * cuda\_warp} & \texttt{(blockDim,)} & \texttt{($n_1$ * 32,)} \\
  &|& \texttt{$n_1$ * cuda\_warpgroup} & \texttt{(blockDim,)} & \texttt{($n_1$ * 128,)} \\
  &|& \texttt{$n_1$ * cuda\_threads\_strided($n_2$, $n_3$)} & \texttt{(blockDim/$n_3$, $n_3$)} & \texttt{($n_1$, $n_2$)} \\
  &|& \texttt{$n_1$ * cuda\_warp\_in\_cluster} & \texttt{(clusterDim, blockDim)} & \texttt{($n_1$, 32)} \\
  &|& \texttt{$n_1$ * cuda\_cta\_in\_cluster} & \texttt{(clusterDim * blockDim,)} & \texttt{($n_1$ * blockDim,)} \\
  &|& \texttt{cuda\_cluster} & \texttt{(clusterDim * blockDim,)} & \texttt{(clusterDim * blockDim,)} \\
  &|& \texttt{$n_1$ * cuda\_cta\_in\_cluster\_strided($n_3$)} & \texttt{(ClusterDim/$n_3$, $n_3$, blockDim)} & \texttt{($n_1$, 1, blockDim)} \\
  &|& \texttt{$n_1$ * cuda\_warp\_in\_cluster\_strided($n_3$)} & \texttt{(clusterDim/$n_3$, $n_3$, blockDim)} & \texttt{($n_1$, 1, 32)} \\
  &|& \texttt{cuda\_agnostic\_sub\_cta} & \texttt{(clusterDim, blockDim)} & \texttt{(1, $\top$)} \\
  &|& \texttt{cuda\_agnostic\_intact\_cta} & \texttt{(clusterDim, blockDim)} & \texttt{($\top$, blockDim)} \\
\bottomrule
\end{tabular}
}

The conversion to a collective type may or may not be \textit{aligned} and may or may not be \textit{1-padded}.
The steps to unpack a collective type from a collective unit are

\begin{itemize}
  \item Substitute concrete values for \lighttt{clusterDim} and \lighttt{blockDim}.
    This converts the domain and box into tuples of rational numbers or $\top$.
  \item Fail if any non-$\top$ coordinate is not a natural number, or if $B_i \ne \top \land B_i \notin [1, D_i]$ for any box coordinate $B_i$ and corresponding domain coordinate $D_i$.
  \item Remove any domain coordinates $D_i$ with $D_i = 1$ and remove corresponding box coordinates $B_i$ (it must be the case that $B_i = 1$ or $B_i = \top$ by the above check).
  \item Initialize the collective type $\delta$ with the box and domain.
  \item Let $f = \frac{\texttt{clusterDim * blockDim}}{\delta.D_0 \times \delta.D_1 \times ...}$; fail if $f \notin \mathbb{N}$.
  \item If $f > 1$, prepend $f$ to $\delta.D$, and prepend $1$ or $\top$ to $\delta.B$, for the 1-padded and non-1-padded cases, respectively.
  \item If the conversion is \textit{aligned}, reshape (Section~\ref{sec:CollTypeReshape}) until the collective type is in aligned form (def~\ref{sec:gAlignedForm}); fail if this cannot be done.
  \item \textbf{NOTE:} not all of these failures seem to be checked by Exo-GPU today.
\end{itemize}

\mainKey{Example 1:} Suppose \lighttt{clusterDim = 2}, \lighttt{blockDim = 256}, and the collective unit has domain (\lighttt{blockDim},), box (128,).

If we have alignment and 1-padding, then
\begin{itemize}
  \item Substitution gives $\delta.D = (256,)$, $\delta.B = (128,)$.
  \item No domain coordinates are 1.
  \item $f = 2$, so we prepend $2$ to $\delta.D$ and $1$ to $\delta.B$ (since 1-padding is on).
    Now $\delta.D = (2, 256)$ and $\delta.B = (1, 128)$.
  \item Since we have alignment, split dimension 1 by 128 to get the final collective type $\delta$, with $\delta.D = (2, 2, 128)$ and $\delta.B = (1, 1, 128)$.
\end{itemize}
If we have neither alignment nor 1-padding, then the result would instead be $\delta.D = (2, 256)$ and $\delta.B = (\top, 128)$.

\mainKey{Example 2:} Suppose \lighttt{clusterDim = 8}, \lighttt{blockDim = 384}, and the collective unit has domain (\lighttt{clusterDim}, \lighttt{blockDim}) and box (2, 128).

If we have alignment, then
\begin{itemize}
  \item Substitution gives $\delta.D = (8, 384), \delta.B = (2, 128)$.
  \item No domain coordinates are 1.
  \item $f = 1$, so no change needed.
  \item Since we have alignment, we do two splits to get $\delta.D = (4, 2, 3, 128)$ and $\delta.B = (1, 2, 1, 128)$.
\end{itemize}
If we don't have alignment, then the result would instead be $\delta.D = (8, 384)$ and $\delta.B = (2, 128)$.
1-padding does not impact this result.

\mainKey{Example 3:} Suppose \lighttt{clusterDim=1}, \lighttt{blockDim = 128}, and the collective unit has domain $(\lighttt{clusterDim}, \lighttt{blockDim})$ and box $(1, \top)$.
\begin{itemize}
  \item Substitution gives $\delta.D = (1, 128), \delta.B = (1, \top)$.
  \item Remove the $0^{th}$ dimension as $\delta.D_0 = 1$. So $\delta.D = (128,), \delta.B = (\top,)$.
  \item $f = 1$, so no change needed.
\end{itemize}
Alignment and 1-padding don't affect this example.
The unpacked collective type is always $\delta.D = (128,), \delta.B = (\top,)$.

\subsection{CPU Scope}
\label{sec:gCpuScope}

Statements outside of a \lighttt{CudaDeviceFunction} block (def~\ref{sec:gCudaDeviceFunction}) are at CPU scope.

\subsection{CTA}
\label{sec:gCta}
Cooperative thread array, also known as a ``thread block''.
Group of \lighttt{blockDim}-many CUDA threads that execute concurrently on the same SM, and can be synchronized with \lighttt{\_\_syncthreads()} in CUDA C++.

Exo-GPU only parallelizes on the x-dimension, so \lighttt{threadIdx.x} identifies a thread within a CTA; it ranges from 0 to \lighttt{blockDim - 1}.

\subsection{CUDA Device Function Block}
\label{sec:gCudaDeviceFunction}

Statement that launches its body as a CUDA device function (``kernel''/``grid'') (Section~\ref{sec:CudaDeviceFunction}).

\input{b_samples/CudaDeviceFunction.0.tex}

The above example may be scheduled using

\input{b_samples/CudaDeviceFunction_scheduling.0.tex}

\subsection{CUDA Scope}
\label{sec:gCudaScope}

Statements within a \lighttt{CudaDeviceFunction} block (def~\ref{sec:gCudaDeviceFunction}) are at CUDA scope.

% >D

\subsection{Device Task}
\label{sec:gDeviceTask}

The body of the inner-most \lighttt{cuda\_tasks} loop is a device task (see~\ref{sec:gCudaDeviceFunction}).

\subsection{Domain}
\label{sec:gDomain}

Attribute $\delta.D$ of a collective type $\delta$ and attribute $\omega.D$ of a collective tiling $\omega$.
Both are of type $\mathbb{N}_{\ge2}^M$ for some dimension $M: \mathbb{N}$.
This describes the arrangement of threads within a cluster into an $M$-dimensional grid via the \textsf{toLocal} function (def~\ref{sec:gToLocal}).

% >E
% >F
% >G
% >H
% >I
% >J
% >K
% >L

\subsection{Local Thread Index}
\label{sec:gLocalThreadIndex}

0-based integer index uniquely identifying a thread within a cluster.
The threads are indexed lexicographically by (CTA index, thread index in CTA).
The closed-form equation is \lighttt{cluster\_ctarank * blockDim.x + threadIdx.x}

\subsection{Loop Mode}
\label{sec:gLoopMode}

Each Exo loop has an included loop mode object, which is one of these Python objects:
\begin{itemize}
  \item \lighttt{Seq(pragma\_unroll: Optional[int])}: sequential loop.
  \item \lighttt{Par()}: OpenMP parallel-for.
  \item \lighttt{CudaTasks()}: distribute iterations (device tasks,~\ref{sec:gDeviceTask}) to CUDA clusters.
  \item \lighttt{CudaThreads(unit: CollUnit)}: distribute iterations to thread collectives within a cluster.
\end{itemize}
This does not affect the sequential semantics of the loop.

The respective frontend syntax is

\input{b_samples/loop_modes.0.tex}

Scheduling functions:
\begin{itemize}
  \item \texttt{set\_loop\_mode}: use new loop mode object.
  \item \texttt{update\_loop\_mode}: modify attribute of loop mode.
  \item \texttt{parallelize\_loop}: use \lighttt{Par()} as the loop mode (legacy).
\end{itemize}

% >M
% >N
% >O
% >P
% >Q

\subsection{Qualitative Timelines (QualTL)}
\label{sec:gQualTL}

Additional description on each memory access, beyond the IDs of the thread(s) performing the access.

\input{spork_b_QualTL.tex}

% >R
% >S

\subsection{Statement Instance}
\label{sec:gStatementInstance}

A \emph{statement} is a syntactic construct, while a \emph{statement instance} is a single interpretation/``execution'' of a statement. For example, ``\lighttt{for i in seq(0, 10): $s_1$; $s_2$}'' is a loop containing two statements: $s_1$ and $s_2$, and when the loop is executed, 20 statement instances are created (10 instances of $s_1$ and 10 instances of $s_2$).

\subsection{Sync Timeline (SyncTL)}
\label{sec:gSyncTL}

Parameter for synchronization statements (\lighttt{Fence}, \lighttt{Arrive}, \lighttt{Await}), which are defined as a composition of a \myKeyA{full timeline set} (set of \textsf{QualTL}), \myKeyA{temporal timeline set} (set of \textsf{QualTL}), and \myKeyA{transitivity flag} (bool).

We list the sync timelines in the following table, where ``temp.'' in a qualitative timeline's column indicates membership of the qualitative timeline in the sync timeline's temporal timeline set, ``full.'' indicates membership in the temporal timeline set and full timeline set, and ``(transitive)'' indicates the sync timeline has its transitivity flag set to true.

{
\setlength{\tabcolsep}{2pt}
\small
\begin{tabular}{|r|l l|l l|l l l| l l l l|}
\hline
$\tau_s$ & cpu & strm & cuda1 & cuda2 & Sm80 & tmaS & tmaG & wgA & wgD & wgS & wg0 \\
\hline
\texttt{empty\_sync\_tl} &  &  &  &  &  &  &  &  &  &  & \\
\texttt{cpu\_in\_order} (transitive) & full &  &  &  &  &  &  &  &  &  & \\
\texttt{cuda\_stream\_sync} (transitive) &  & full & full & full & full & full & full & full & full & full & \\
\texttt{cuda\_in\_order} (transitive) &  & temp. & full & full & temp. & temp. & temp. & temp. & temp. & temp. & temp.\\
\texttt{cuda\_temporal} &  & temp. & temp. & temp. & temp. & temp. & temp. & temp. & temp. & temp. & temp.\\
\texttt{Sm80\_cp\_async} &  &  &  &  & full &  &  &  &  &  & \\
\texttt{Sm80\_generic} &  & temp. & full & full & full & temp. & temp. & temp. & temp. & temp. & temp.\\
\texttt{tma\_to\_smem\_async} &  &  &  &  &  & full &  &  &  &  & \\
\texttt{tma\_to\_gmem\_async} &  &  &  &  &  &  & full &  &  &  & \\
\texttt{wgmma\_async\_smem} &  &  &  &  &  &  &  &  &  & full & \\
\texttt{wgmma\_fence\_1} &  &  & full &  &  &  &  & full & full &  & \\
\texttt{wgmma\_fence\_2} &  &  &  &  &  &  &  & full & full &  & \\
\texttt{wgmma\_async} &  &  &  &  &  &  &  & full & full & full & \\
\texttt{cuda\_async\_proxy} &  &  &  &  &  & full & full &  &  & full & \\
\texttt{cuda\_async\_proxy\_wgmma} &  &  &  &  &  & full & full & full & full & full & \\
\texttt{cuda\_generic\_and\_async\_proxy} &  & temp. & full & full & full & full & full & temp. & temp. & full & temp.\\
\hline
\end{tabular}
}

\input{spork_b_QualTL.tex}

\subsection{Synchronization Statement}
\label{sec:gSyncStmt}

One of

\hphantom{spacing}
\texttt{Fence($\tau_s^\mathrm{pre}, \tau_s^\mathrm{post}$)}
\hfill
\texttt{Arrive($\tau_s^\mathrm{pre}$) >}\texttt{> $z$}
\hfill
\texttt{Await($z, \tau_s^\mathrm{post}, n$)}
\hphantom{spacing}

where $\tau_s^\mathrm{pre}$ and $\tau_s^\mathrm{post}$ are \myKeyA{sync timelines} (\textsf{SyncTL}, \ref{sec:gSyncTL}), which filter the set of qualitative timelines of memory accesses that are synchronized, and $z$ and $n$ are a barrier variable read and an integer, which together control pairing of executed \lighttt{Arrive} and \lighttt{Await} instances.

Scheduling functions:
\begin{itemize}
  \item \texttt{insert\_barrier\_alloc}: insert allocation of a barrier variable
  \item \texttt{insert\_fence}
  \item \texttt{insert\_arrive}
  \item \texttt{insert\_await}
\end{itemize}


% >T
\subsection{Thread Collective}
\label{sec:gThreadCollective}

Set of threads assigned to execute one statement instance (def~\ref{sec:gStatementInstance}).
On the CUDA device, the threads in the thread collective are uniquely identified by its cluster index (which is not statically analyzed) and its local thread index (def~\ref{sec:gLocalThreadIndex}), which is analyzed by collective analysis (Section~\ref{sec:CollTiling}).
In the context of the abstract machine, the cluster index is replaced with a task index, since the mapping betwveen tasks and clusters is a hardware-dependent detail we abstract over.

\subsection{Thread Pitch (Set)}
\label{sec:gThreadPitch}

The thread pitch is used in multiple contexts.
In all cases, it describes the ``distance'', in local thread indices (def~\ref{sec:gLocalThreadIndex}), between adjacent items of some sort.

\mainKey{\texttt{cuda\_threads} Loop Iterator:} Let $\mu: \mathcal{P}(\mathbb{N})$ be the local thread indices of the thread collective executing the 0th iteration of the loop.
The local thread indices of the thread collective execucting the $j^{th}$ iteration of the loop are $\{t + jp \mid t \in \mu\}$, $p$ being the thread pitch of the loop iterator.
If the loop has no more than 1 iteration, then the thread pitch of the loop iterator is 0.

\mainKey{Distributed Memory:} Let $\mu: \mathcal{P}(\mathbb{N})$ be the local thread indices of the thread collective allocating the physical memory holding $x[0, ..., 0]$, and let the deduced thread pitch tuple for the variable $x$ be $(p_0, ..., p_{M-1})$.
Then the local thread indices of the thread collective for $x[i_0, i_1, ...]$ are
\begin{equation*}
  \left \{ t + \sum_{k=0}^{M-1} p_k i_k \mid t \in \mu \right \}
\end{equation*}

\mainKey{Domain:} For a domain $(D_0, ..., D_{M-1})$, we define respective dimension thread pitch values as
\begin{equation*}
    P_m = \prod_{k=m+1}^{M-1} D_k
\end{equation*}
As a shorthand, we say $\delta.P_k$ or $\omega.P_k$ to mean the $k^{th}$ dimension thread pitch defined above, with respect to $\delta.D$ or $\omega.D$.
The thread pitch set of $D$ is $\{P_0, ..., P_{M-1}\}$; note $P_{M-1} = 1$ always.

\mainKey{Collective Tiling/Type:} The thread pitch set of a collective tiling/type is that of its domain.

\subsection{toLocal}
\label{sec:gToLocal}

We define the mapping $\mathsf{toLocal}: \mathbb{N}^M \to \mathbb{N}^M \to \mathbb{N}$, which converts a domain (def~\ref{sec:gDomain}) and coordinates to a local thread index, as
\begin{align*}
    \mathsf{toLocal}((D_0,...,D_{M-1}), (c_0,...,c_{M-1})) \mapsto \sum_{k=0}^{M-1} c_k \times D_{k+1} \times ... \times D_{M-1}
\end{align*}
i.e. the coordinates $[0, D_0-1]_\mathbb{N} \times ... \times [0, D_{M-1}-1]_\mathbb{N}$ get mapped to local thread indices (def~\ref{sec:gLocalThreadIndex}) in lexicographical order.
For this definition to work as expected, the product of the domain coordinates $D_0 \times ... \times D_{M-1}$ must be equal to the number of threads in the cluster (\lighttt{clusterDim.x * blockDim.x}).

% >U
% >V
% >W

\subsection{Warp}
\label{sec:gWarp}

32 CUDA threads with consecutive \lighttt{threadIdx.x} values, aligned so that the lowest index is a multiple of 32.
(Note, this is simplified from the real CUDA definition, which takes into account the y and z dimensions that Exo-GPU does not parallelize on).

\subsection{Warp Variable}
\label{sec:gWarpVariable}

The warp variables for a specific CUDA device function are specified by the \lighttt{warp\_config: List[CudaWarpConfig]} parameter of \lighttt{CudaDeviceFunction}.
This specifies a name and register count for a certain number of warps in the CTA.
See example~\ref{sec:gCudaDeviceFunction}, Section~\ref{sec:CudaDeviceFunction}.

If \lighttt{blockDim} is given instead of \lighttt{warp\_config}, then there's implicitly a single warp variable with name \lighttt{""}, warp count $\lighttt{blockDim}/32$, and no register count modification.

The ``prefix'' of a warp variable is the sum of the warp counts of the warp variables specified before itself.

The CUDA device function is compiled separately for each warp variable, with code paths for other warp variables statically elimintated.

\subsection{Warpgroup}
\label{sec:gWarpgroup}

128 CUDA threads with consecutive \lighttt{threadIdx.x} values, aligned so that the lowest index is a multiple of 128.
(Note, this is simplified from the real CUDA definition, which takes into account the y and z dimensions that Exo-GPU does not parallelize on).

% >X
% >Y
% >Z

\end{document}
